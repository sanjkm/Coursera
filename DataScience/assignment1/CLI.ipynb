{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls /data/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -du -h /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -help ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls -R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs dfs -ls ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs dfs -ls /data/wiki\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls /data/wiki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls -R /data/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -less /data/wiki/en_articles_part/articles-part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -tail /data/wiki/en_articles_part/articles-part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -head /data/wiki/en_articles_part/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -head /data/wiki/en_articles_part/articles-part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - root supergroup          0 2017-11-28 21:41 /data\n",
      "drwxr-xr-x   - root supergroup          0 2017-10-17 13:11 /user\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - jovyan supergroup          0 2017-11-28 21:41 /user/jovyan\r\n",
      "-rw-r--r--   1 jovyan supergroup        239 2017-11-28 21:41 /user/jovyan/README.md\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls -R /user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: `/user/joyvan/README.md': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -less /data/wiki/en_articles_part/articles-part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## How to use LTI interface\r\n",
      "\r\n",
      "This is an environment for your practice with HDFS.\r\n",
      "You can create Jupyter notebook and practice with different HDFS shell commands.\r\n",
      "\r\n",
      "* The sample dataset is located at /data/wiki/en_articles_part in the HDFS.\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat /user/jovyan/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239  README.md\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                     Size      Used     Available  Use%\r\n",
      "hdfs://localhost:9000  459885248512  77520896  425615577088    0%\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                Size    Used  Available  Use%\r\n",
      "hdfs://localhost:9000  428.3 G  73.9 M    396.4 G    0%\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! hdfs dfs -touchz newfile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   1 jovyan supergroup        239 2017-11-28 21:41 README.md\r\n",
      "-rw-r--r--   1 jovyan supergroup          0 2018-01-14 17:22 newfile.txt\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get: `README.md': File exists\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -get README.md  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jovyan : users\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-c92a128df021>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-c92a128df021>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    hdfs setrep\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "hdfs setrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not find or load main class setrep\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs setrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: hdfs fsck <path> [-list-corruptfileblocks | [-move | -delete | -openforwrite] [-files [-blocks [-locations | -racks | -replicaDetails]]]] [-includeSnapshots] [-storagepolicies] [-blockId <blk_Id>]\r\n",
      "\t<path>\tstart checking from this path\r\n",
      "\t-move\tmove corrupted files to /lost+found\r\n",
      "\t-delete\tdelete corrupted files\r\n",
      "\t-files\tprint out files being checked\r\n",
      "\t-openforwrite\tprint out files opened for write\r\n",
      "\t-includeSnapshots\tinclude snapshot data if the given path indicates a snapshottable directory or there are snapshottable directories under it\r\n",
      "\t-list-corruptfileblocks\tprint out list of missing blocks and files they belong to\r\n",
      "\t-files -blocks\tprint out block report\r\n",
      "\t-files -blocks -locations\tprint out locations for every block\r\n",
      "\t-files -blocks -racks\tprint out network topology for data-node locations\r\n",
      "\t-files -blocks -replicaDetails\tprint out each replica details \r\n",
      "\t-storagepolicies\tprint out storage policy summary for the blocks\r\n",
      "\t-blockId\tprint out which file this blockId belongs to, locations (nodes, racks) of this block, and other diagnostics info (under replicated, corrupted or not, etc)\r\n",
      "\r\n",
      "Please Note:\r\n",
      "\t1. By default fsck ignores files opened for write, use -openforwrite to report such files. They are usually  tagged CORRUPT or HEALTHY depending on their block allocation status\r\n",
      "\t2. Option -includeSnapshots should not be used for comparing stats, should be used only for HEALTH check, as this may contain duplicates if the same file present in both original fs tree and inside snapshots.\r\n",
      "\r\n",
      "Generic options supported are\r\n",
      "-conf <configuration file>     specify an application configuration file\r\n",
      "-D <property=value>            use value for given property\r\n",
      "-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.\r\n",
      "-jt <local|resourcemanager:port>    specify a ResourceManager\r\n",
      "-files <comma separated list of files>    specify comma separated files to be copied to the map reduce cluster\r\n",
      "-libjars <comma separated list of jars>    specify comma separated jar files to include in the classpath.\r\n",
      "-archives <comma separated list of archives>    specify comma separated archives to be unarchived on the compute machines.\r\n",
      "\r\n",
      "The general command line syntax is\r\n",
      "command [genericOptions] [commandOptions]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs fsck -files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   1 jovyan supergroup        239 2017-11-28 21:41 README.md\r\n",
      "-rw-r--r--   1 jovyan supergroup          0 2018-01-14 17:22 newfile.txt\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## How to use LTI interface\r\n",
      "\r\n",
      "This is an environment for your practice with HDFS.\r\n",
      "You can create Jupyter notebook and practice with different HDFS shell commands.\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -cat README.md | head -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-4208e8fc8675>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-4208e8fc8675>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    head README.md\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "head README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-9134e0fdf78d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-9134e0fdf78d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tail README.md\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tail README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## How to use LTI interface\r\n",
      "\r\n",
      "This is an environment for your practice with HDFS.\r\n",
      "You can create Jupyter notebook and practice with different HDFS shell commands.\r\n",
      "\r\n",
      "* The sample dataset is located at /data/wiki/en_articles_part in the HDFS.\r\n"
     ]
    }
   ],
   "source": [
    "! head README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## How to use LTI interface\r\n",
      "\r\n",
      "This is an environment for your practice with HDFS.\r\n",
      "You can create Jupyter notebook and practice with different HDFS shell commands.\r\n",
      "\r\n",
      "* The sample dataset is located at /data/wiki/en_articles_part in the HDFS.\r\n"
     ]
    }
   ],
   "source": [
    "! tail README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* The sample dataset is located at /data/wiki/en_articles_part in the HDFS.\r\n"
     ]
    }
   ],
   "source": [
    "! tail -1 README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/data/wiki/en_articles_part/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! ls /data/wiki/en_articles_part/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/data/wiki/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! ls /data/wiki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "drwxrwxrwx   - jovyan supergroup          0 2017-11-28 21:41 /data/wiki/en_articles_part\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /data/wiki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-25-6f64687968ce>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-25-6f64687968ce>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    hdfs dfs -du\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "hdfs dfs -du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239  README.md\r\n",
      "0    newfile.txt\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail: `/data/wiki/en_articles_part/en_articles_part': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -tail /data/wiki/en_articles_part/en_articles_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "-rwxrwxrwx   1 jovyan supergroup   76861985 2017-11-28 21:41 /data/wiki/en_articles_part/articles-part\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /data/wiki/en_articles_part/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erson, An Outline of General Ethics, Rome, Urbaniana University Press, 2004. John Paul II, Encyclical Letter Veritatis Splendor, 6-8-1993. D'Urance, Michel, Jalons pour une éthique rebelle, Aléthéia, Paris, 2005. John Newton, Ph.D. Complete Conduct Principles for the 21st Century, 2000. ISBN 0967370574. External links                  An Introduction to Ethics by Paul Newall, aimed at beginners. Ethics, 2d ed., 1973. by William Frankena Ethics Bites, Open University podcast series podcast exploring ethical dilemmas in everyday life. National Reference Center for Bioethics Literature World's largest library for ethical issues in medicine and biomedical research Ethics entry in Encyclopædia Britannica by Peter Singer The Philosophy of Ethics on Philosophy Archive Kirby Laing Institute for Christian Ethics Resources, events, and research on a range of ethical subjects from a Christian perspective. International Association for Geoethics (IAGETH) International Association for Promoting Geoethics (IAPG)      \r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -tail /data/wiki/en_articles_part/articles-part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
